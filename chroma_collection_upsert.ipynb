{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b277149d-1760-4eac-a651-8fe9e1e56ccd",
   "metadata": {},
   "source": [
    "# Collecting all of the player rules and guides for a TTRPG\n",
    "\n",
    "If I change the name this can be used to scrap a directory of pdf documents and add them to a collection.  Works best with pdf files that are easily readable by pypdf2.  Note that the cleaning steps are not ideal for arvix papers and would need changing to make better use of them.  Additionally section tags and paragraph tags should be added to the metadata for better context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f249b934-21e6-462b-89a3-1ede8ad00b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "import time\n",
    "import json\n",
    "import re\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from PyPDF2 import PdfReader\n",
    "import chromadb\n",
    "from chromadb.config import Settings\n",
    "\n",
    "pdf_directory = \"./pdfs/Rules\"\n",
    "bestiary_directory = \"./pdfs/Bestiary\"\n",
    "\n",
    "persistant_directory = \"./chroma\"\n",
    "client = chromadb.Client(Settings(chroma_db_impl=\"duckdb+parquet\", persist_directory=persistant_directory))\n",
    "collection_name = \"dnd_documents\"\n",
    "collection = client.create_collection(collection_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f83a4a6-33dc-43f3-ac3b-e10547e0adcc",
   "metadata": {},
   "source": [
    "# Helper functions\n",
    "\n",
    "Beware the commented code.  It will delete your collection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7871b21a-6535-4de6-99c0-b34f1379fcab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#client.delete_collection(collection_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec6f05e1-d5b7-4d62-a49d-ffa92033d489",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_list(directory_path):\n",
    "    return [f for f in os.listdir(directory_path) if f.endswith(\".pdf\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6aceea8-7384-428a-88ce-a55bc040c3d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_key(page_index, sentence_index, prefix=None):\n",
    "    if prefix is not None:\n",
    "        return prefix + \"_p\" + str(page_index) + \"_s\" + str(sentence_index)\n",
    "    else:\n",
    "        return \"p\" + str(page_index) + \"_s\" + str(sentence_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a02e707f-ccb7-4c99-ac78-362cb07bb100",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_page_to_sentences(page, page_index, line_min_length=5, name_in_key=None):\n",
    "    sentences_tuples = list()\n",
    "    page_text = page.extract_text()\n",
    "    lines = page_text.splitlines()\n",
    "    page_text = \"\\n\".join([line for line in lines if len(line.split()) > line_min_length])  # only take lines that are larger than k\n",
    "    page_text = re.sub(r'E L T[\\W\\w]*\\n', ' ', page_text)  # E L T pattern removed.  used in the pdf for tables\n",
    "    page_text = re.sub(r'[\\n]|[  ]|[â€¢ ]', ' ', page_text)  # Remove line breaks, double spaces, and dots\n",
    "    page_text = re.sub(r'(?!\\.)  (?!\\.)', ' ', page_text)  # Remove double spaces in between letters\n",
    "    sentences = page_text.split('.')  # break into sentences\n",
    "    sentences = [sentence.strip() + \".\" for sentence in sentences if len(sentence) > 1]  # re-add \".\" to the end of the sentence\n",
    "    for sentence_index, sentence in enumerate(sentences):\n",
    "        sentences_tuples.append((build_key(page_index, sentence_index, name_in_key), sentence, page_index, sentence_index))\n",
    "    return sentences_tuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8eacb83-aa71-4d99-8f90-ed3d4100c6bf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def pdf_to_document_tuples(file_path, line_min_length=5, name_in_key=None):\n",
    "    sentences_tuples = []\n",
    "    \n",
    "    pdf_reader = PdfReader(file_path)\n",
    "    pages = pdf_reader.pages\n",
    "    for page_index, page in tqdm(enumerate(pages)):\n",
    "        new_tuples = tokenize_page_to_sentences(page, page_index, line_min_length, name_in_key=name_in_key)\n",
    "        for t in new_tuples:\n",
    "            sentences_tuples.append(t)\n",
    "        \n",
    "    return sentences_tuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e2af5e2-734d-45a7-b869-982bd1daa704",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_column_from_tuples(tuples_list, column_index):\n",
    "    return [tuples[column_index] for tuples in tuples_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "259722ce-a410-4859-980c-a11773000d0c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def vectorize_pdfs_in_directory_to_chroma(directory_path, collection):\n",
    "    files = get_file_list(directory_path)\n",
    "    \n",
    "    for file in tqdm(files):\n",
    "        # Get all documents in directory, tokenize them into sentences for embedding\n",
    "        document_tuples = pdf_to_document_tuples(os.path.join(directory_path,file), name_in_key=file)\n",
    "        # I pass a tuple for the extra metadata.  This used to be in the id of the call and required additional parsing after query.\n",
    "        document_keys = get_column_from_tuples(document_tuples, 0)\n",
    "        document_sentences = get_column_from_tuples(document_tuples, 1)\n",
    "        document_page_index = get_column_from_tuples(document_tuples, 2)\n",
    "        document_sentence_index = get_column_from_tuples(document_tuples, 3)\n",
    "        # Create metadata\n",
    "        metadata = [{\"file_name\":file, \"page_index\":document_page_index[i], \"sentence_index\":document_sentence_index[i]} for i in range(len(document_page_index))]\n",
    "        # Add to chroma collection\n",
    "        collection.add(documents=document_sentences, metadatas=metadata, ids=document_keys)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b57d6d89-4e58-4e4d-aa85-c8fe49cb089d",
   "metadata": {},
   "source": [
    "# Embedding to chroma."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec823a64-9e65-49ed-aae1-b36be547f6df",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Take all documents in a directory and add it to the chroma vector database\n",
    "vectorize_pdfs_in_directory_to_chroma(pdf_directory, collection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e73e548d-ea5f-4854-80f7-bc63c9e8f282",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "872ad7da-7033-44e8-896e-ae7c47e49563",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check just to see if it's there\n",
    "collection.query(query_texts=[\"critical hit\"], n_results=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a49215-78ac-4915-8f29-aff2c9c257aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_page(directory_path, file_name, page_number):\n",
    "    pdf_reader = PdfReader(os.path.join(directory_path, file_path))\n",
    "    return pdf_reader.pages[page_number]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7556239d-d415-40ed-bd54-7de3f7272496",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_close_sentences(directory_path, file_name, page_number, sentence_number):\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e4143c-a735-48f3-aed0-48c3ca50a9ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c5bae4d-9e75-4a65-8c28-7e4faeccd5ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45375a52-ad98-4851-8bb8-1221dfc6e9bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa5a5ad-d5cd-4a02-bf6b-c81b6d5168b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e91accd8-e18d-4807-9887-d68b51100835",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7aeffd7-42af-4e1d-9103-f55281f45ef3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9353edee-eea4-452e-a6c1-760875c064e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pinecone-chroma",
   "language": "python",
   "name": "pinecone-chroma"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
