{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcacccc6-0f3a-4338-8a34-4b0818426e98",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "import time\n",
    "import datetime\n",
    "import json\n",
    "\n",
    "import pinecone\n",
    "import openai\n",
    "\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "pinecone_api_key = os.getenv(\"PINECONE_API_KEY\")\n",
    "\n",
    "embedding_dimensions = 1536\n",
    "model_engine = \"text-embedding-ada-002\"\n",
    "pinecone_name = \"dnd-rules-lawyer\"\n",
    "pinecone_region = \"asia-southeast1-gcp\" # Pinecone calls this the environement ? strange\n",
    "\n",
    "pinecone.init(api_key=pinecone_api_key, environment=pinecone_region)\n",
    "index = pinecone.Index(pinecone_name)\n",
    "openai.api_key = openai_api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5277bf22-0252-45f4-944d-5554483383cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_metadata(content, user, vector):\n",
    "    create_time = time.time()\n",
    "    return {\n",
    "        \"Timestamp\": create_time,\n",
    "        \"User\": \"User\",\n",
    "        \"Message\": content,\n",
    "        \"Datetime\": datetime.datetime.fromtimestamp(create_time),\n",
    "        \"Vector\": vector\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4141377-ad3d-4439-8257-f639014fb763",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_message_hash(content):\n",
    "    return hash(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f19c3e6-3dfd-452b-98cd-8a03aba8968e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_openai_embeddings(content, engine=\"text-embedding-ada-002\"):\n",
    "    content = content.encode(encoding=\"ASCII\", errors=\"ignore\").decode()  # fix unicode errors\n",
    "    response = openai.Embedding.create(input=content, engine=engine)\n",
    "    vector = response['data'][0]['embedding']\n",
    "    return vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa721f93-1fc5-4aff-9fc7-d48f03abe7db",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def openai_completion(prompt, model=\"gpt-3.5-turbo\", temperature=0, top_p=1.0, max_tokens=400, freq_pen=0.0, pres_pen=0.0, stops=[\"USER:\"], max_retry=5):\n",
    "        retry = 0\n",
    "        prompt = prompt.encode(encodding=\"ASCII\", errors=\"ignore\").decode()\n",
    "        while True:\n",
    "            try:\n",
    "                response = openai.Completion.create(\n",
    "                    model=model,\n",
    "                    prompt=prompt,\n",
    "                    temperature=temperature,\n",
    "                    max_tokens=max_tokens,\n",
    "                    top_p=top_p,\n",
    "                    frequency_penalty=freq_pen,\n",
    "                    presence_penalty=pres_pen,\n",
    "                    stops=stops\n",
    "                )\n",
    "                text = response[\"choices\"][0][\"text\"].strip()\n",
    "                text = re.sub(r'[\\r\\n]+', \"\\n\", text)\n",
    "                text = re.sub(r'[\\t]+', \" \", text)\n",
    "                filename = f'{time.time()}_gpt35_turbo.txt'\n",
    "                if not os.path.exists('gpt3_logs'):\n",
    "                    os.makedirs(\"gpt3_logs\")\n",
    "                    \n",
    "            except Exception as e:\n",
    "                retry += 1\n",
    "                if retry >= max_retry:\n",
    "                    return f\"GPT3 error: {e}\"\n",
    "                print(\"Error in communication with openai.\")\n",
    "                time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe6e7ca1-83e8-4abd-abe4-3cbf3c65b79f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_conversation(results):\n",
    "    result = list()\n",
    "    for m in results[\"matches\"]:\n",
    "        info = load_json(f'conversations/{m[\"id\"]}.json')\n",
    "        result.append(info)\n",
    "    ordered = sorted(result, key=lambda d: d['time'], reverse=False)\n",
    "    messages = [i[\"message\"] for i in ordered]\n",
    "    return \"\\n\".join(messages).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d1b13f5-e602-4e5e-b82b-2d8d80f1b97f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_prompt(file_name):\n",
    "    with open(file_name) as open_file:\n",
    "        return open_file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2111b79-af9c-43ba-b9bf-2f14e77a8cc5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def save_json(file_name, content):\n",
    "    with open(file_name, \"w+\") as f:\n",
    "        json.dump(content, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d7550b5-e508-4035-98d7-95918d162458",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "get_prompt(\"prompt.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "594352d5-f9f4-47ea-ac97-e28a758417cf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "user = \"USER\"\n",
    "top_k = 15\n",
    "prompt_file = \"prompt.txt\"\n",
    "logs_path = \"./logs\"\n",
    "\n",
    "\n",
    "while True:\n",
    "    payload = list()\n",
    "    \n",
    "    # Message Meta\n",
    "    message = input(\"\\n\\n USER: \")\n",
    "    message_hash = create_message_hash(message)\n",
    "\n",
    "    # Create embedding of new message\n",
    "    message_vector = get_openai_embeddings(message)\n",
    "    \n",
    "    # Save metadata about vector\n",
    "    metadata = create_metadata(message, user, vector)\n",
    "    save_json(logs_path, metadata)\n",
    "    \n",
    "    # Append to payload for later indexing\n",
    "    # Send to Pinecone after gpt message\n",
    "    payload.append((message_hash, message_vector))\n",
    "    \n",
    "    # Query for relevant messages, generate response\n",
    "    results = index.query(vector=vector, top_k=top_k)\n",
    "    conversation = load_conversation(results)\n",
    "    prompt = get_prompt(prompt_file).replace(\"<PREVIOUS_CONVERSATION>\")\n",
    "    \n",
    "    # Generate the response from the large lang model\n",
    "    output = gpt3_completion(prompt)\n",
    "    output_hash = (output)\n",
    "    \n",
    "    # Embed the output\n",
    "    output_vector = get_openai_embeddings(output)\n",
    "    \n",
    "    # Save the output metadata\n",
    "    metadata = create_metadata(message, user, vector)\n",
    "    save_json(logs_path, metadata)\n",
    "    \n",
    "    # Append to the payload the response from gpt\n",
    "    payload.append((output_hash, output_vector))\n",
    "    \n",
    "    # Upsert to the pinecone database\n",
    "    index.upsert(payload)\n",
    "    \n",
    "    # Print responce to the message\n",
    "    print(f'\\n\\n {output}')\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pinecone-chroma",
   "language": "python",
   "name": "pinecone-chroma"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
